{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31611006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ermil\\anaconda3\\envs\\torchenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import nltk\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3dfa270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "330f957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sshleifer/distilbart-xsum-12-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc34c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.59k/1.59k [00:00<?, ?B/s]\n",
      "C:\\Users\\ermil\\anaconda3\\envs\\torchenv\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ermil\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading pytorch_model.bin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 443M/443M [01:07<00:00, 6.56MB/s] \n",
      "Downloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26.0/26.0 [00:00<00:00, 26.0kB/s]\n",
      "Downloading (‚Ä¶)olve/main/vocab.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 899k/899k [00:00<00:00, 2.56MB/s]\n",
      "Downloading (‚Ä¶)olve/main/merges.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 456k/456k [00:00<00:00, 5.56MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e00b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_enxoder_length =1024\n",
    "max_decoder_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "859bbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8dd5cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wiki_lingua (C:/Users/ermil/.cache/huggingface/datasets/wiki_lingua/english/1.1.1/6fdaa844abe35a3a2a79e5a1cf9e546f32ad234d59756bcf9cfeadff6c89240e)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('wiki_lingua', name = lang, split = 'train[:2000]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd358f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'article'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33dc7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus) -> dict:\n",
    "    return {\"document\": corpus[\"article\"][\"document\"],\n",
    "        \"summary\": corpus[\"article\"][\"summary\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58a4dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\ermil\\.cache\\huggingface\\datasets\\wiki_lingua\\english\\1.1.1\\6fdaa844abe35a3a2a79e5a1cf9e546f32ad234d59756bcf9cfeadff6c89240e\\cache-e02963387f4edd20.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = data.map(preprocess_corpus, remove_columns=['article', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "746b63fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Laptop GPU'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "103e76cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Walk to the venue where you will be drinking if it is close enough. Take public transit. Show up in style by hiring a limo or black car service. Flag a taxi cab for a convenient option to get where you‚Äôre going. Request a rideshare service like Uber or Lyft using an app on your phone. Reserve a designated driver service.',\n",
       " 'Plan in advance. Assign a designated driver. Leave your car at home. Leave the venue with your designated driver.',\n",
       " 'Pay attention to your body. Give up your keys. Listen to other people. Accept help. Stay where you are. Have an emergency back-up plan. Make sure that your phone is charged.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d93e7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2samples(example):\n",
    "    documents = []\n",
    "    summaries = []\n",
    "    for sample in zip(example[\"document\"], example[\"summary\"]):\n",
    "        if len(sample[0]) > 0:\n",
    "            documents += sample[0]\n",
    "            summaries += sample[1]\n",
    "    return {\"document\": documents, \"summary\": summaries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69c20636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\ermil\\.cache\\huggingface\\datasets\\wiki_lingua\\english\\1.1.1\\6fdaa844abe35a3a2a79e5a1cf9e546f32ad234d59756bcf9cfeadff6c89240e\\cache-4a248abe970dba8d.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(list2samples, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3bdb520",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_txt, validation_data_txt = dataset.train_test_split(test_size=0.1).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c39f805f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['document', 'summary'],\n",
       "     num_rows: 4351\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['document', 'summary'],\n",
       "     num_rows: 484\n",
       " }))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_txt, validation_data_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76dea0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
    "    source, target = batch[\"document\"], batch[\"summary\"]\n",
    "    source_tokenized = tokenizer(source, padding=\"max_length\", truncation=True, max_length=max_source_length)\n",
    "    target_tokenized = tokenizer(target, padding=\"max_length\", truncation=True, max_length=max_target_length)\n",
    "    batch = {k: v for k, v in source_tokenized.items()}\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
    "        for l in target_tokenized[\"input_ids\"]\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9472cbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data = train_data_txt.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "        batch, tokenizer, max_enxoder_length, max_decoder_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=train_data_txt.column_names,\n",
    ")\n",
    "\n",
    "validation_data = validation_data_txt.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "         batch, tokenizer, max_enxoder_length, max_decoder_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=validation_data_txt.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c5f89fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ermil\\AppData\\Local\\Temp\\ipykernel_19196\\1250854224.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "metric = datasets.load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf99a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2b50e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "220ba12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir =\"results\" ,\n",
    "    num_train_epochs=1,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,\n",
    "    gradient_checkpointing=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=validation_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "805c4e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msouth_memphis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ermil\\wandb\\run-20231015_105546-75lkqc0c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/south_memphis/huggingface/runs/75lkqc0c' target=\"_blank\">pleasant-donkey-28</a></strong> to <a href='https://wandb.ai/south_memphis/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/south_memphis/huggingface' target=\"_blank\">https://wandb.ai/south_memphis/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/south_memphis/huggingface/runs/75lkqc0c' target=\"_blank\">https://wandb.ai/south_memphis/huggingface/runs/75lkqc0c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1088' max='1088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1088/1088 3:14:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.635200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.722900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.301300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.141200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.993400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.920200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.810900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.838900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.732600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.686700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.685700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.583800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.660200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.528200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.587600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.534700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.531800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1088, training_loss=4.891310986350565, metrics={'train_runtime': 11715.8106, 'train_samples_per_second': 0.371, 'train_steps_per_second': 0.093, 'total_flos': 4489876617560064.0, 'train_loss': 4.891310986350565, 'epoch': 1.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cff1391f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 16:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.389221668243408,\n",
       " 'eval_rouge1': 31.6002,\n",
       " 'eval_rouge2': 12.3369,\n",
       " 'eval_rougeL': 25.5388,\n",
       " 'eval_rougeLsum': 30.627,\n",
       " 'eval_gen_len': 21.8079,\n",
       " 'eval_runtime': 1033.032,\n",
       " 'eval_samples_per_second': 0.469,\n",
       " 'eval_steps_per_second': 0.117,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c84fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bb62427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"document\"],\n",
    "        truncation=True,\n",
    "        max_length=max_enxoder_length,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "test_samples = validation_data_txt.select(range(5))\n",
    "summaries_after_tuning = generate_summary(test_samples, model)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "904556f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Id  Summary after\n",
      "----  ------------------------------------------------------------------------------------------------------------\n",
      "   0  Say what you want to be nice. Try a different approach to your demands. Ask for help. Be stubborn.\n",
      "   1  Put your foot on the edge of the brake. Put your foot back on the side of the scooter.\n",
      "   2  Look for the Forest Longhorn Beetle woodworm. Inspect the woodworm species. Look for a woodworm to the wood.\n",
      "   3  Get plenty of sleep. Get a quiet spot. Eat healthy foods. Take a break.\n",
      "   4  Read the care label. Read a test spot.\n",
      "\n",
      "Target summaries:\n",
      "\n",
      "  Id  Target summary\n",
      "----  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  Be a broken record. Refuse to move until you get what you want. Completely ignore the person who doesn‚Äôt agree with you. Bargain. Get emotional. Don‚Äôt forget your reasons for wanting what you want.\n",
      "   1  Place your dominant foot on the back of the scooter deck. Place your other foot on the scooter deck next to your dominant foot. Place your hands on the handle bar grips. Kick off with your back foot.\n",
      "   2  Look for the Forest Longhorn Beetle woodworm. Search for Waney Edge Borer woodworm. Spot Ambrosia Beetle woodworm. Look for Wood Boring Weevil woodworms. Detect Powder Post Beetle woodworm. Look for Deathwatch Beetle woodworm.\n",
      "   3  Take care of your physical needs before working. Find a quiet and comfortable work space. Put away your phone and other distractions. Energize yourself with water and healthy snacks. Take frequent breaks while you work. Switch between different tasks to help you stay sharp.\n",
      "   4  Check the clothing label. Read the product information. Test on a small area. Remove any excess dirt or grass.\n",
      "\n",
      "Source documents:\n",
      "\n",
      "  Id  Document\n",
      "----  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  So you‚Äôve tried to be nice, and that has gotten you nowhere. If you feel like you‚Äôve tried being diplomatic, kind, and understanding and you‚Äôre no better off than you were when you started, then you may need to take a different approach. Sure, you may be a bit annoying by being a broken record and repeating what you want again and again, but who says it won‚Äôt help you get what you want?‚Äù  Continue saying what you want, or talking about what you want, until the person you‚Äôre talking to is so frustrated with you or annoyed that he just gives in. Sure, it won‚Äôt be pretty, but it‚Äôll help you get closer to where you need to go. Just fold your arms over your chest and say what you want. Be firm in what you believe and don‚Äôt be ashamed of acting this way! If you‚Äôve tried to be nice, then you need to try a different approach. Another way to be truly stubborn is simply not to budge until the person you‚Äôre with gives in to your demands. This can mean staying in your seat at a restaurant long after you‚Äôve eaten your meal, staying at home when you and the person you‚Äôre with need to get going somewhere, or even stopping and sitting down on the ground wherever you want until you get what you want. Sure, this may embarrass the person you‚Äôre with, but if you really don‚Äôt care about that, then this may be the best way to get what you‚Äôre asking for!  This can be especially effective if the person is really depending on you to get up, like if you‚Äôre supposed to be giving him a ride somewhere. Sure, this may not be the most sophisticated approach, but it may be the most effective. Some people will quickly give in in the face of embarrassment. Another way to be stubborn is to just ignore the person who is telling you you can‚Äôt do a certain thing. Act like you literally can‚Äôt hear the person until he or she lets you have what you want. This can mean blankly staring at the person in front of you, as if you don‚Äôt hear him or her turning you down at all, putting your fingers in your ears and saying, ‚ÄúI can‚Äôt hear you!‚Äù or just shrugging and walking away. Sure, this isn‚Äôt the world‚Äôs most mature approach, but if you‚Äôre really determined to get what you want, then this may help you get it at any cost. Another way to be stubborn and to get whatever you want is to bargain with the person you‚Äôre asking for help. Think for a minute and see if there‚Äôs something you can do for the person, so it feels less like a give give, and more like a give and take. If you have some ideas for how you can be of use to the person, then this will make it feel more like an exchange than a case of you just getting what you want.  For example, you can ask your mother to let you hang out with your friends in exchange for doing the laundry over the weekend for her. This will make your question much more appealing. If you want to borrow your sister‚Äôs sweater, offer to let her borrow the new dress of yours that she really likes. Though this is a cheap trick, sometimes shedding a tear or two can help you get what you want, especially if you‚Äôre in public. If your parents, siblings, or person you‚Äôre with won‚Äôt let you get your way, try getting really upset, crying, throwing a bit of a fit, or just showing how much you want whatever you‚Äôre not getting. Not only will this emphasize how much you want to get whatever you‚Äôre asking for, but it will also have the bonus effect of embarrassing the person you‚Äôre with into letting you have your way.  If you don‚Äôt care about embarrassing yourself, try asking for whatever you want in an extra public place and then have a meltdown when you don‚Äôt get what you want so the person you‚Äôre with gets extra embarrassed. If this doesn‚Äôt backfire and make the person even more angry with you, it can actually be just embarrassing enough that you may win. You can practice your hissy fit in advance if you think that‚Äôll make your act more convincing. At the end of the day, being stubborn is all about sticking to your guns and getting what you want‚Äîand what you deserve. If you lose sight of your goals or needs, then you‚Äôll be likely to give in to people or to give up because it‚Äôs simply easier than creating conflict. However, if you repeat what you want and why you want it to yourself, or even write it down on a piece of paper and read it over periodically, then you‚Äôll be more likely to be stubborn about what you want‚Äîand to get it.  Sure, it‚Äôs easier to shrug your shoulders and say that you‚Äôll be okay with not getting what you want, but if that‚Äôs your attitude, then you‚Äôll never be happy. Remember that being stubborn is a good thing when it comes to following your heart and asking for what you really want in life. Be proud of yourself for being firm, sticking up for yourself, and not letting other people boss you around.\n",
      "   1  You want your foot to be at a 45 degree angle with the edge of the deck. The outer edge of your foot should be right up against the edge of the brake.  If you‚Äôre regular footed (your right foot is dominant), your legs and feet should be turned toward the right side of the scooter. If you‚Äôre goofy footed (your left foot is dominant), your legs and feet should be turned toward the left side of the scooter. Your big toe on your dominant foot should be lined up with the groove on the inside of your other foot. The inner edges of both of your feet should be touching. Wrap your fingers around the grips so you have a firm hold on the handle bars. Use your back foot to propel yourself forward whenever you want the scooter to move. Place your foot back on the deck in the same position it was in before.\n",
      "   2  The Forest Longhorn Beetle and its larvae are only found on trees in the forest. Look for large bore holes that can be up to 10 mm (3/8 inch) across, much larger than most household woodworms. Note that tunnels will be very discreet and run against the grain of the wood. Waney Edge Borer woodworm can be found in wood that has bark on it, and is rarely found in homes. Look for borer dust with bun-shaped pellets around the bark areas from the boring holes. The holes are usually around 2 mm (1/16 inches) in diameter. Ambrosia Beetle woodworm is generally found in the forest; this woodworm can‚Äôt survive in treated lumber, and only lives outdoors. Unlike other woodworm species, the adult does the tunneling, going against the grain and deep into the wood.  Look for black-colored tunnels that are evident after trees are damaged or wood is cut (in a lumber yard, for example.) Wood Boring Weevil woodworm can be found in wood damaged by fungal decay. You can identify this woodworm by looking for tiny holes with ragged bore holes and coarse dust. Look for tunnels that run against the grain and often break the surface of the damaged wood. Powder post woodworm is generally found in seasoned hardwood, which is usually only found in furniture factories and lumber yards. These woodworms tunnel along the grain of the wood, and don‚Äôt attack old wood (wood that is more than 15 years old). Look for tiny entry and exit bore holes no larger than 2 mm (1/16 inch), and loose, flour-like dust. Deathwatch Beetle woodworm can be found in hardwood, (usually oak), that is partially decayed. Look for bore holes that measure up to 3 mm (1/8 inch) across, and boring dust containing large bun-shaped pellets that are visible without any magnification. If possible, inspect the interior of the wood; more extensive damage occurs inside the wood than what is visible externally.\n",
      "   3  It‚Äôs hard to concentrate on homework if you‚Äôre tired, hungry, or uncomfortable. Try to get plenty of sleep if you know you‚Äôll have to do a bunch of homework the next day, and don‚Äôt try to work on an empty stomach or with a full bladder!  If you feel physically tense, do some yoga or light stretches before you begin to work. Doing breathing exercises can also help you feel more comfortable and alert. If you‚Äôre not already in comfy clothes, get changed before you start working. This may mean joggers, sweatpants, pjs, shorts, underwear, or even being completely naked. It's your choice. Your environment can make a big difference in how well you focus on your work. Before you begin doing your homework, find a spot that is quiet, well-lit, and gives you plenty of space to spread out.  You‚Äôll want a place where you can sit comfortably, but don‚Äôt get too comfortable. If you do homework in bed or on a cozy couch, you may be tempted to fall asleep! If you have to work at home, ask anyone who lives with you to give you a little quiet time while you do your homework. If you‚Äôre constantly looking at your Facebook feed or checking your Instagram notifications, you won‚Äôt get much work done. Put your phone in a place where you can‚Äôt get at it easily, like inside your bag or in a desk drawer. Turn off notifications if they distract you.  If you can‚Äôt resist messing around on your phone or visiting time-wasting websites on your computer, consider installing an app or a browser extension that blocks tempting apps and sites. Don‚Äôt try to work with a TV or radio on. If you listen to music while you do your homework, choose something that‚Äôs quiet and not too exciting, like some gentle classical music. While you study, keep a bottle of water and some snacks on hand. Staying hydrated and eating healthy foods can help you wake up, focus, and stay alert. Choose foods that can help boost your brain power, such as:  Whole grains Healthy proteins, like fish, beans, or nuts Blueberries Leafy greens You‚Äôll get burnt out and lose focus quickly if you try to work too long without a break. Try working for an hour to an hour and a half and then taking a 15-minute break. This will give your tired brain a chance to rest and recharge.  During your breaks, you can go for a walk, have a snack, do a little meditation, or even put your head down for a quick power nap. You can also use your breaks to reward yourself with a fun video or a quick game on your phone. If you‚Äôve reached the point where you can‚Äôt stand to look at your assignment any more, take a break and then try switching to another task for a while. This way you can give your brain a break (and get some variety) while still being productive.  For example, if you‚Äôve been working on an essay for an hour or two, take a break and then switch to doing some math problems. Don‚Äôt try to do more than one task at once, though. Trying to multitask will disrupt your focus and cause you to make more mistakes.\n",
      "   4  On the inside of your garment, there is a care label. Reading this label will give you an idea of what you can use on your garment safely. For example, an empty triangle is the symbol for bleach. If the triangle is black with a large ‚ÄúX‚Äù through it, you cannot use bleach of any sort. If the triangle is striped black and white, you can use non-chlorine bleach only. Before using any cleaning product or detergent, read the label. The label can help identify which products are best for which garment. It can also tell you if it is safe on the type of garment you are using. For example, a detergent with bleach will be best for a white garment, but may not be the best choice for a dark colored garment. Before putting anything on a stained item of clothing, do a test spot first. A test spot will allow you to check that you can use your stain removal solution on the clothing without causing permanent damage like changing the colour. The inside hem is a great location to test a solution because it is very inconspicuous. Before doing anything with your item, you should remove excess dirt or grass from the stained location. Blot, rather than rub, to try get the excess out. Rubbing will only cause the stain to move further into your clothing. Struggling to get some dirt off? Try holding the clothing taut between your fingers, and flicking from the inside of the garment. This should forcefully fling off any excess mud.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tabulate(\n",
    "        zip(\n",
    "            range(len(summaries_after_tuning)),\n",
    "            summaries_after_tuning,\n",
    "            \n",
    "        ),\n",
    "        headers=[\"Id\", \"Summary after\"],\n",
    "    )\n",
    ")\n",
    "print(\"\\nTarget summaries:\\n\")\n",
    "print(\n",
    "    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n",
    ")\n",
    "print(\"\\nSource documents:\\n\")\n",
    "print(tabulate(list(enumerate(test_samples[\"document\"])), headers=[\"Id\", \"Document\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a9c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
