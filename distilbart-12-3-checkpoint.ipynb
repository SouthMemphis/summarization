{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62dfc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import nltk\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9c3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac9cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162a9b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sshleifer/distilbart-xsum-12-3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5501160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d605c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_enxoder_length =1024\n",
    "max_decoder_length = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc008e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wiki_lingua (C:/Users/ermil/.cache/huggingface/datasets/wiki_lingua/english/1.1.1/6fdaa844abe35a3a2a79e5a1cf9e546f32ad234d59756bcf9cfeadff6c89240e)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('wiki_lingua', name = lang, split = 'train[:2000]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f531e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'article'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1979e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus) -> dict:\n",
    "    return {\"document\": corpus[\"article\"][\"document\"],\n",
    "        \"summary\": corpus[\"article\"][\"summary\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ce3664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\ermil\\.cache\\huggingface\\datasets\\wiki_lingua\\english\\1.1.1\\6fdaa844abe35a3a2a79e5a1cf9e546f32ad234d59756bcf9cfeadff6c89240e\\cache-e02963387f4edd20.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = data.map(preprocess_corpus, remove_columns=['article', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98530f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Laptop GPU'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab093164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'summary'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7689d92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Walk to the venue where you will be drinking if it is close enough. Take public transit. Show up in style by hiring a limo or black car service. Flag a taxi cab for a convenient option to get where you’re going. Request a rideshare service like Uber or Lyft using an app on your phone. Reserve a designated driver service.',\n",
       " 'Plan in advance. Assign a designated driver. Leave your car at home. Leave the venue with your designated driver.',\n",
       " 'Pay attention to your body. Give up your keys. Listen to other people. Accept help. Stay where you are. Have an emergency back-up plan. Make sure that your phone is charged.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f03dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2samples(example):\n",
    "    documents = []\n",
    "    summaries = []\n",
    "    for sample in zip(example[\"document\"], example[\"summary\"]):\n",
    "        if len(sample[0]) > 0:\n",
    "            documents += sample[0]\n",
    "            summaries += sample[1]\n",
    "    return {\"document\": documents, \"summary\": summaries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ab4eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\ermil\\.cache\\huggingface\\datasets\\wiki_lingua\\english\\1.1.1\\6fdaa844abe35a3a2a79e5a1cf9e546f32ad234d59756bcf9cfeadff6c89240e\\cache-4a248abe970dba8d.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(list2samples, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c5480b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_txt, validation_data_txt = dataset.train_test_split(test_size=0.1).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc14624a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['document', 'summary'],\n",
       "     num_rows: 4351\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['document', 'summary'],\n",
       "     num_rows: 484\n",
       " }))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_txt, validation_data_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9da4c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
    "    source, target = batch[\"document\"], batch[\"summary\"]\n",
    "    source_tokenized = tokenizer(source, padding=\"max_length\", truncation=True, max_length=max_source_length)\n",
    "    target_tokenized = tokenizer(target, padding=\"max_length\", truncation=True, max_length=max_target_length)\n",
    "    batch = {k: v for k, v in source_tokenized.items()}\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
    "        for l in target_tokenized[\"input_ids\"]\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b40ab9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data = train_data_txt.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "        batch, tokenizer, max_enxoder_length, max_decoder_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=train_data_txt.column_names,\n",
    ")\n",
    "\n",
    "validation_data = validation_data_txt.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "         batch, tokenizer, max_enxoder_length, max_decoder_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=validation_data_txt.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81a64c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ermil\\AppData\\Local\\Temp\\ipykernel_11016\\1250854224.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "metric = datasets.load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56875bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b380d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75896ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir =\"results\" ,\n",
    "    num_train_epochs=1,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=3, \n",
    "    per_device_eval_batch_size=3,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,\n",
    "    gradient_checkpointing=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=validation_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "830cea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msouth_memphis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\ermil\\wandb\\run-20231014_150724-detmyp7i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/south_memphis/huggingface/runs/detmyp7i' target=\"_blank\">different-snowball-27</a></strong> to <a href='https://wandb.ai/south_memphis/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/south_memphis/huggingface' target=\"_blank\">https://wandb.ai/south_memphis/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/south_memphis/huggingface/runs/detmyp7i' target=\"_blank\">https://wandb.ai/south_memphis/huggingface/runs/detmyp7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1451' max='1451' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1451/1451 5:59:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.468400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.877900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.625900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.598600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.456100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.425500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.448300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.305800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.164200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.235900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.191900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>4.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.095200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.201700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.191900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.115400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.154700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.056500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1451, training_loss=4.428775562244312, metrics={'train_runtime': 21565.4451, 'train_samples_per_second': 0.202, 'train_steps_per_second': 0.067, 'total_flos': 5387912164147200.0, 'train_loss': 4.428775562244312, 'epoch': 1.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "998513f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [162/162 20:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.950443983078003,\n",
       " 'eval_rouge1': 35.3713,\n",
       " 'eval_rouge2': 13.777,\n",
       " 'eval_rougeL': 27.9843,\n",
       " 'eval_rougeLsum': 34.0308,\n",
       " 'eval_gen_len': 26.6281,\n",
       " 'eval_runtime': 1212.9193,\n",
       " 'eval_samples_per_second': 0.399,\n",
       " 'eval_steps_per_second': 0.134,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "600bc1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1910743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(test_samples, model):\n",
    "    inputs = tokenizer(\n",
    "        test_samples[\"document\"],\n",
    "        truncation=True,\n",
    "        max_length=max_enxoder_length,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(device)\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return outputs, output_str\n",
    "\n",
    "\n",
    "model_before_tuning = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "test_samples = validation_data_txt.select(range(5))\n",
    "summaries_after_tuning = generate_summary(test_samples, model)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a772bffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Id  Summary after\n",
      "----  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  Start working on your project in advance. Use a step sequencer. Select a mixer. Use the Riff Machine.\n",
      "   1  Decide whether you need to say anything. Avoid criticism that goes for someone's personality. Adjust your expectations. Avoid making assumptions about someone's character.\n",
      "   2  Use green tea bags. Apply peppermint oil. Apply a cold compress.\n",
      "   3  Understand the purpose of a medical second opinion. Ask for a second opinion if you are concerned about your child’s condition.\n",
      "   4  Check the color inversion. Rasterize a layer. Select the layer.\n",
      "\n",
      "Target summaries:\n",
      "\n",
      "  Id  Target summary\n",
      "----  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  Follow your plan to build your song in FL Studio. Compose. Sequence. Arrange. Mix. Utilize pre-made patterns.\n",
      "   1  Think before you speak. Be realistic. Depersonalize other people's actions. Separate the individual from their actions. Focus on positives.\n",
      "   2  Try a green tea compress. Apply an ice compress. Use aromatherapy.\n",
      "   3  Understand what is meant by \"a second opinion\". Be informed about who can request a second opinion. Evaluate whether you have valid reasons for wanting a second opinion. Recognize that there are poor reasons for wanting a second opinion.\n",
      "   4  Know the inversion command. Invert colors in a specific layer. Invert specific parts of a layer.\n",
      "\n",
      "Source documents:\n",
      "\n",
      "  Id  Document\n",
      "----  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "   0  It's best to plan your song in advance, and start working on it the next time you have a whole day to work on it in one sitting. If you can leave your computer in sleep mode, you may leave your project overnight and come back to it at a later time. You can enter notes directly through the piano roll. Alternatively, you can play music live using a controller keyboard. The step sequencer plays percussion samples, and you can record with Step Recording on the Recording Panel. A sequencer is an interface that records, edits, and plays back audio samples. The recording and playback features of a sequencer is one of the biggest advantages of composing digitally, rather than with individual analog instruments.  Left-click on step-sequencer squares to turn them on, and right click to turn them off. To change patterns, go to the Pattern Selector in the toolbar, and slide (left-click and hold) squares up and down. You have a lot of freedom here in FL Studio. You can arrange clips in any order you like and overlay clips as well. You can even think of clips like notes in the piano roll.  Use the Playlist window to make your clip arrangements. There, you can add, delete, slice (Fruity Slicer!), rearrange, or mute clips. Left click an instrument channel button in the channel rack to select a mixer track, which will then be highlighted with a green fader. This is where all the sound from your instruments is routed. So, think of the mixer as a filter you can use to modify sound as it travels through the mixer.  Use the mixer for levels and effects, such as reverb and delay. These effects are also automatable.   Recorded sound will be displayed in the Playlist as an Audio Clip. Use the Playlist window to play back audio and rearrange clips. In any channel, you can go to the Piano Roll window and the Tools menu to select the Riff Machine. This includes a wide variety of riffs, chords, and arpeggios that you can adjust. As opposed to building music note by note, riffs offer depth through multiple notes, and chords add multiple notes played simultaneously.  Click Throw Dice to begin a new melody/beat, and then click Accept to add it to Piano Roll.  Try pre-recorded chords. Also in the Piano Roll Tools Menu, find the Chords submenu. Here, you can add chords to the Piano Roll without having to create and play them manually.\n",
      "   1  Before you dish out criticism, pause and consider whether you really need to say anything at all. If someone did something to get on your nerves, do you really need to point it out? Sometimes, it's best to let small indiscretions go. Try taking a few deep breaths and leaving the room instead of criticizing.  It's best not to criticize someone's personality. People have very little control over personality quirks. If your friend Jane has a tendency to get caught up in her own interests, it might be best to just smile and nod while she's going on and on about a new TV show she loves. If this is just something she does, criticizing it will probably not result in the behavior changing.  Avoid criticism that goes for someone's personality over his or her actions. For example, it may be a problem that your boyfriend forgets to pay his phone bill on time each month. However, saying something like \"Why are you so forgetful?\" isn't terribly productive. It may be best to be quiet for now and later, when you're calm, talk about finding productive ways to better manage bill payment, such as downloading a phone app that will provide a reminder when it is time to pay the phone bill every month. Critical people often have very high expectations of those around them. It's possible your tendency to criticize stems from expecting too much from those around you. If you find yourself consistently annoyed or disappointed with others, it may be a good idea to adjust your expectations.  Think about the last time you criticized someone. What lead to this criticism? Were your expectations in the situation realistic? For example, say you criticized your girlfriend for not answering your texts quickly enough when she was out with friends. You told her this made you feel uncared for and that she should have answered right away. Pause and examine these expectations. Can you really expect your girlfriend to be on her phone when she's socializing? Isn't your girlfriend entitled to a social life outside of your relationship? You have probably occasionally missed texts or returned them late if you were busy. In this case, maybe you could adjust your expectations. It may not be reasonable to expect a text returned immediately if you know your girlfriend is hanging out with other people. Oftentimes, critical people have a tendency to personalize events that occur around them. This can bleed out into personalizing the actions of others. If someone gets on your nerves or makes your life difficult, you may feel the urge to criticize that person. However, remember other people have their own separate lives and struggles. If someone did something to bother you, the majority of the time their actions were not directed at you.   For example, say you have a friend who routinely cancels plans. You may take this as an act of disrespect and feel compelled to criticize that person for not valuing your relationship. However, realistically your friend's actions are probably not personal. Look at the situation from an outside perspective. Is your friend very busy? Is she just generally a flaky person? Is your friend more introverted than others? A variety of factors may make a person cancel plans often. Chances are, it isn't about you personally. Criticizing may add more stress to someone whose life is already stressful. Critical people are often guilty of filtering. This means you only focus on the negative aspects of a situation or a person, failing to see good qualities alongside negative ones. This may lead to your criticizing others. If you find yourself making assumptions about a person's character, stop yourself. Try to separate a frustrating action from the person doing the action. We all behave poorly sometimes, but a single action is not a reflection of character.   If you see someone cut in line, do you immediately think that person is rude? If so, stop for a moment and reconsider. Maybe that person is in a hurry. Maybe he has a lot on his mind, and he did not realize he cut. You can be frustrated by the action. Getting cut in line is annoying. However, try not to judge a stranger's character based on the action.  If you work on separating the person from the action, you may naturally want to criticize less. As you come to realize you cannot judge a person's character based on a single choice or decision, you will be unable to call someone out for being rude or disrespectful. Oftentimes, being critical results from how you're choosing to see a situation. Everyone has flaws and imperfections. However, the vast majority of people have good qualities that outweigh these flaws. Try to focus on a person's positive qualities over their negative ones.   Having a positive attitude can change the way you react to stress. Negative emotions activate the amygdala, which is a major trigger of feelings of stress an anxiety. If you're feeling keyed up yourself, this can lead to negative interactions with others. Working on developing a positive attitude can help you stop criticizing others.  Believe everyone has some natural goodness in them. While you may be skeptical of this fact, try giving everyone the benefit of the doubt in this regard. Go out of the way to look for people doing good in the world. Focus on the person in the supermarket who told the cashier to have a nice day. Pay attention to the coworker who always smiles at you on your way to your desk.  Oftentimes, people's flaws actually stem from other, positive qualities. For example, your boyfriend may take a long time to complete basic household tasks. This could be because he's more conscientious than others. Maybe he spends an extra 20 minutes doing the dishes because he makes the effort to get them extra clean.\n",
      "   2  Green tea contains polyphenols that have anti-inflammatory and antioxidant compounds that are helpful for your skin. Take a tea bag and steep it in hot water.  Gently squeeze out any excess water and allow the bag to cool.  Once the bag has cooled down, apply the bag to your pimple.  Leave the bag on for 15 minutes and rinse your face with water when you are done. You can also put green tea bags under your eyes to decrease puffiness or relieve tired eyes. If you feel a pimple coming or your pimple is painful, use an ice compress instead of heat. Icing can reduce swelling, inflammation, redness, and pain. Wrap some ice in a thin washcloth and apply to your pimple.  Leave it on for one minute and then wait five minutes.  Reapply for another minute if you need to.  You can also apply an ice compress after a warm compress if your pimple does not come to a head.  You can apply ice directly to your skin, just not for very long. A cold compress can also be used to relieve bug bites. Apply the compress for 15 minutes a few times a day.  If you have dry, itchy skin, apply the compress to the irritated areas. Smelling rosemary or lavender essential oil for 5 minutes has been shown to reduce stress. Applying peppermint oil to your skin can be used to relieve tension headaches. Put 5 to 10 drops of the oil in 1 to 2 cups of water. Then saturate a washcloth in the mixture.  Wring out the washcloth and then apply to your body.\n",
      "   3  A medical second opinion does not mean that you will see another doctor regularly. Its main purpose is to get medical information or opinions about a health problem from a physician other than the regular doctor who has been providing care. The regular doctor may be your pediatrician, family physician, or a sub-specialist. Second opinions (consultations) may be obtained for several reasons:  To identify or confirm a diagnosis. To help interpret a test result. To provide additional viewpoints and information about risks, benefits, or expected outcomes. To give recommendations regarding treatment choices . To provide an opinion about the need, type, and timing of surgery. To help parents make the decision to change care to another provider. For health issues in infants and children, requests for a second opinion may come from several sources.  A second opinion may be recommended by your pediatrician or family physician, especially when there is an unusual or ill-defined medical problem that is outside your physician’s area of expertise.Your child's regular doctor may also ask for a second opinion if they believe that the input of a specialist will allow him or her to provide better management A consultation may also be requested by your regular doctor when they are treating a condition that is not responding as expected, or when they disagree with opinions or recommendations from another doctor. However, you — as the parents of family members of the child — may also request a second opinion, especially when the child is suffering from a serious condition that requires important or complex decisions. You may also request a second opinion if you are concerned or confused about the diagnosis or treatment recommendations, if you want to be absolutely sure that all treatment options have been considered, or if you want to feel reassured that your child’s medical needs are being addressed in the best possible manner. Before you go ahead with arranging a second opinion, it's a good idea to take a step back and re-examine the situation to ensure that you have a valid option for requesting one.  Some good reasons include:  Your doctor is uncertain about the cause or best treatment of a child’s problem, or your doctor thinks that your child may have a serious or chronic disease which would be better treated by a specialist. An example is a child with diabetes who has been treated by your family physician but is beginning to have more frequent problems with sugar control. You are not sure whether your child’s condition is being treated in the best possible way and want reassurance from another expert. An example is the asthmatic child whose wheezing episodes are becoming more severe, despite following your current doctor's recommendations. Your child’s condition has not had the expected response to a particular therapy, such as elimination of recurring serious kidney infections. Sometimes parents want to seek a second opinion on their child's condition just because their current doctor tells them something that they don't want to hear. Although this is understandable, it is not a good reason for seeking a second opinion and is often just a waste of time. Other poor reasons for getting a second opinion include:  “Shopping around” to find someone who agrees with your own opinion.  Perhaps you are consulting with doctors until you find one that, like you, also opposes giving childhood immunizations You are hoping to get “better news” about a recent serious diagnosis. You are trying to delay the need to make an important treatment decision.\n",
      "   4  Inverting colors in Photoshop is as simple as the command Ctrl+I or Cmd+I, but there are a few things to check about your file and layers before you can get the color inversion exactly where you want it. To invert the entire image, simple open the image in Photoshop, and press Crtl+I or Cmd+I. If you want to invert colors in a specific layer in your Photoshop file: select that layer, and make sure it is rasterised. If not, right-click on the Layer label (under the Layers list) and select \"Rasterise Layer\". Once you ensure the layer is rasterised, you can press Ctrl+I to invert all visible colors in the layer.  You can only perform this on one layer at a time. It will not work if you have selected multiple layers. You should perform this step after you re-size the layer or image to the size that you want. Enlarging an image after rasterizing could lead to pixelation and a loss in resolution. If you want to invert specific parts of a layer, you can select the layer, and select the portion you want to invert using different selection tools available in Photoshop: try the Rectangle tool, Lasso tool, or Magic Wand. Add or subtract portions to your selection, as needed. When you are satisfied with the selection area you have created, press Ctrl+I to invert. You can also select different portions one at a time and invert. However, if you select a previously inverted portion a second time by mistake, that set of pixels will be reverted to original color. Thus, it is better to invert for complete selection in one go.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tabulate(\n",
    "        zip(\n",
    "            range(len(summaries_after_tuning)),\n",
    "            summaries_after_tuning,\n",
    "            \n",
    "        ),\n",
    "        headers=[\"Id\", \"Summary after\"],\n",
    "    )\n",
    ")\n",
    "print(\"\\nTarget summaries:\\n\")\n",
    "print(\n",
    "    tabulate(list(enumerate(test_samples[\"summary\"])), headers=[\"Id\", \"Target summary\"])\n",
    ")\n",
    "print(\"\\nSource documents:\\n\")\n",
    "print(tabulate(list(enumerate(test_samples[\"document\"])), headers=[\"Id\", \"Document\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6b167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
